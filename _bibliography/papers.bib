@inproceedings{AxCore,
  title={AxCore: A Quantization-Aware Approximate GEMM Unit for LLM Inference},
  author={Zou†, Jiaxiang and Chen†, Yonghao and Chen†, Xingyu and Xu†, Chenxi and Chen, Xinyu},
  booktitle={IEEE/ACM International Symposium on Microarchitecture (MICRO)},
  year={2025},
  note={(to appear)}
}

@inproceedings{X-SET,
  title={X-SET: An Efficient Graph Pattern Matching Accelerator With Order-Aware Parallel Intersection Units},
  author={Xu†, Chenxi and Chen, Xinyu and Shi, Tianhui and Sun, Shixuan and Zhai, Jidong},
  booktitle={IEEE/ACM International Symposium on Microarchitecture (MICRO)},
  year={2025},
  note={(to appear)}
}


@inproceedings{OA-LAMA,
author = {Chen†, Huangxu and Hao, Yingbo and Chen, Xinyu and Zou, Yi},
title = {OA-LAMA: An Outlier-Adaptive LLM Inference Accelerator with Memory-Aligned Mixed-Precision Group Quantization},
year = {2025},
booktitle = {Proceedings of the 44rd IEEE/ACM International Conference on Computer-Aided Design},
series = {ICCAD '25},
note={(to appear)}
}


@inproceedings{Graphitron,
author = {Zhang, Xinmiao and Feng, Zheng and Liang, Shengwen and Chen, Xinyu and Zhang, Lei and Liu, Cheng},
title = {Graphitron: A Domain Specific Language for FPGA-Based Graph Processing Accelerator Generation},
year = {2025},
isbn = {9798400719219},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3735452.3735533},
doi = {10.1145/3735452.3735533},
abstract = {Due to hardware customization capabilities, FPGA-based graph processing accelerators achieve significantly higher energy efficiency than many general-purpose computing engines. However, designing these accelerators remains a substantial challenge for high-level users. To overcome the programming barrier, FPGA-based accelerator design frameworks on top of generic graph processing programming models have been developed to automate accelerator generation through pre-built templates. However, they often tightly couple graph processing algorithms, programming models and processing paradigms, and accelerator architectures, which severely limits the expression scope of the algorithms and may also restrict the performance when the generated accelerators fail to suit dynamic processing patterns of the graph processing algorithms.    In this work, we propose Graphitron, a domain-specific language (DSL) that enables the automatic generation of FPGA-based graph processing accelerators without engaging with the complexities of low-level FPGA designs. Graphitron defines vertices and edges as primitive data types and enables users to implement graph processing algorithms by performing various functionalities on top of these primitive data, which greatly eases the algorithm descriptions for high-level users. During compilation, the graph processing functions are naturally classified into either a vertex-centric processing paradigm or an edge-centric processing paradigm according to the target data types, enabling the generation of accelerator kernels of different characteristics. In addition, because of the explicit binding between the graph processing functions and the data types, the Graphitron compiler can automatically infer the computing and memory access patterns of each processing function within graph processing algorithms and apply corresponding hardware optimizations such as pipelining, data shuffling, and caching. Basically, graph semantic information can be utilized to guide algorithm-specific customization of resulting accelerators for higher performance. Our experiments show that Graphitron can generate accelerators for a broader range of graph processing algorithms than prior template-based generation frameworks. Moreover, the accelerators produced by Graphitron achieve performance comparable to, and in some cases exceeding, that of existing frameworks when the combined programming paradigms are beneficial from an algorithmic perspective.},
booktitle = {Proceedings of the 26th ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems},
pages = {28–39},
numpages = {12},
keywords = {Accelerator Generation, Domain-specific Language, FPGA, Graph Processing, High-level Synthesis},
location = {Seoul, Republic of Korea},
series = {LCTES '25}
}

@inproceedings{wu2025apnet,
  title={Rethinking Dynamic Networks and Heterogeneous Computing with Automatic Parallelization},
  author={WU, Ruilong and Li, Xinjiao and Wang, Yisu and Chen, Xinyu and Kutscher, Dirk},
  booktitle={The 9th Asia-Pacific Workshop on Networking (APNet)},
  year={2025},
  note={(to appear)}
}

@inproceedings{chen2025april,
  title={April: Accuracy-Improved Floating-Point Approximation For Neural Network Accelerators},
  author={Chen†, Yonghao and Zou†, Jiaxiang and Chen, Xinyu},
  booktitle={ACM/IEEE Design Automation Conference (DAC)},
  year={2025},
  organization={IEEE},
  pdf={April-DAC25.pdf},
  code={https://github.com/CLabGit/April}
}

@article{yu2025climenti,
  title={Clementi: Efficient Load Balancing and Communication Overlap for Multi-FPGA Graph Processing},
  author={Yu, Feng and Tan, Hongshi and Chen, Xinyu and Chen, Yao and He, Bingsheng and Wong, Weng-Fai},
  journal={Proceedings of the ACM on Management of Data (SIGMOD)},
  year={2025},
  publisher={ACM New York, NY, USA},
  note={(to appear)}
}

@inproceedings{cheng2019deploying,
  title={Deploying hash tables on die-stacked high bandwidth memory},
  author={Cheng, Xuntao and He, Bingsheng and Lo, Eric and Wang, Wei and Lu, Shengliang and Chen, Xinyu},
  booktitle={International Conference on Information and Knowledge Management (CIKM)},
  pages={239--248},
  year={2019},
  code={https://github.com/Xtra-Computing/HashJoin_HMA},
  pdf={cikm19.pdf}
}

@inproceedings{chen2019fly,
  title={On-the-fly parallel data shuffling for graph processing on OpenCL-based FPGAs},
  author={Chen, Xinyu and Bajaj, Ronak and Chen, Yao and He, Jiong and He, Bingsheng and Wong, Weng-Fai and Chen, Deming},
  booktitle={International Conference on Field Programmable Logic and Applications (FPL)},
  pages={67--73},
  year={2019},
  organization={IEEE},
  code={https://github.com/Xtra-Computing/On-the-fly-data-shuffling-for-OpenCL-based-FPGAs},
  pdf={FPL19.pdf}
}

@article{gui2019survey,
  title={A survey on graph processing accelerators: Challenges and opportunities},
  author={Gui, Chuang-Yi and Zheng, Long and He, Bingsheng and Liu, Cheng and Chen, Xin-Yu and Liao, Xiao-Fei and Jin, Hai},
  journal={Journal of Computer Science and Technology},
  volume={34},
  pages={339--371},
  year={2019},
  publisher={Springer US},
  pdf={JCST.pdf}
}

@inproceedings{liu2019obfs,
  title={OBFS: OpenCL based BFS optimizations on software programmable FPGAs},
  author={Liu, Cheng and Chen, Xinyu and He, Bingsheng and Liao, Xiaofei and Wang, Ying and Zhang, Lei},
  booktitle={International Conference on Field-Programmable Technology (FPT)},
  pages={315--318},
  year={2019},
  organization={IEEE},
  code={https://github.com/Liu-Cheng/bfs_with_Intel_OpenCL},
  pdf={OBFS.pdf}
}

@inproceedings{chen2020fpga,
  title={Is FPGA useful for hash joins?},
  author={Chen, Xinyu and Chen, Yao and Bajaj, Ronak and He, Jiong and He, Bingsheng and Wong, Weng-Fai and Chen, Deming},
  booktitle={Conference on Innovative Data Systems Research (CIDR)},
  year={2020},
  code={https://github.com/Xtra-Computing/HashjoinOnHARP},
  pdf={cidr20-join.pdf}
}

@article{liu2020g3,
  title={G3: when graph neural networks meet parallel graph processing systems on GPUs},
  author={Liu, Husong and Lu, Shengliang and Chen, Xinyu and He, Bingsheng},
  journal={Proceedings of the VLDB Endowment (VLDB)},
  volume={13}, 
  number={12},
  pages={2813--2816},
  year={2020},
  publisher={VLDB Endowment},
  code={https://github.com/Xtra-Computing/G3},
  pdf={vldb2020-G3.pdf}
}

@inproceedings{chen2021thundergp,
  title={ThunderGP: HLS-based graph processing framework on FPGAs},
  author={Chen, Xinyu and Tan, Hongshi and Chen, Yao and He, Bingsheng and Wong, Weng-Fai and Chen, Deming},
  booktitle={ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA)},
  pages={69--80},
  year={2021},
  code={https://github.com/Xtra-Computing/ThunderGP},
  pdf={thundergp.pdf}
}

@inproceedings{chen2021skew,
  title={Skew-oblivious data routing for data intensive applications on FPGAs with HLS},
  author={Chen, Xinyu and Tan, Hongshi and Chen, Yao and He, Bingsheng and Wong, Weng-Fai and Chen, Deming},
  booktitle={ACM/IEEE Design Automation Conference (DAC)},
  pages={937--942},
  year={2021},
  organization={IEEE},
  pdf={dac.pdf}
}

@inproceedings{tan2021thundering,
  title={ThundeRiNG: generating multiple independent random number sequences on FPGAs},
  author={Tan, Hongshi and Chen, Xinyu and Chen, Yao and He, Bingsheng and Wong, Weng-Fai},
  booktitle={ACM International Conference on Supercomputing (SC)},
  pages={115--126},
  year={2021},
  code={https://github.com/Xtra-Computing/ThundeRiNG},
  pdf={thundering.pdf}
}

@inproceedings{chen2022regraph,
  title={ReGraph: Scaling Graph Processing on HBM-enabled FPGAs with Heterogeneous Pipelines},
  author={Chen, Xinyu and Chen, Yao and Cheng, Feng and Tan, Hongshi and He, Bingsheng and Wong, Weng-Fai},
  booktitle={IEEE/ACM International Symposium on Microarchitecture (MICRO)},
  pages={1342--1358},
  year={2022},
  organization={IEEE},
  code={https://github.com/Xtra-Computing/ReGraph},
  pdf={regraph.pdf}
}

@article{chen2022thundergp,
  title={ThunderGP: Resource-efficient graph processing framework on FPGAs with HLS},
  author={Chen, Xinyu and Cheng, Feng and Tan, Hongshi and Chen, Yao and He, Bingsheng and Wong, Weng-Fai and Chen, Deming},
  journal={ACM Transactions on Reconfigurable Technology and Systems (TRETS)},
  volume={15},
  number={4},
  pages={1--31},
  year={2022},
  publisher={ACM New York, NY},
  code={https://github.com/Xtra-Computing/ThunderGP/tree/v_HBM},
  pdf={trets22.pdf}
}


@article{tan2023lightrw,
  title={LightRW: FPGA Accelerated Graph Dynamic Random Walks},
  author={Tan, Hongshi and Chen, Xinyu and Chen, Yao and He, Bingsheng and Wong, Weng-Fai},
  journal={Proceedings of the ACM on Management of Data (SIGMOD)},
  volume={1},
  number={1},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY, USA},
  code={https://github.com/Xtra-Computing/LightRW},
  pdf={lightrw.pdf}
}


